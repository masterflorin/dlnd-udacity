{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Deep Learning and what are Neural Networks used for?\n",
    "When thinking about it imagine that you have a plot with a set of blue points and a set of red points (the number doesn't matter), the goal of a neural network in this case is to draw a line to separate between the points. Let's say they represent the admissions for university.\n",
    "\n",
    "The problem we started with is a classification problem, given a point with a certain x,y coordinate that is plotted on a graph, where does the point fall in, is it in the right place? Essentially, we are looking for a way to separate the points and that is a line in our simple example.\n",
    "\n",
    "Now, let's say we draw this line, what we see is that it leaves out some of the blue points moving them to the so-called red region. Our line is the model for our data, and while there are some mistakes it's still doing a good job. However, how did we come up with that line in the first place? While we can eye-ball it, in Deep Learning we'll have to work with algorithms and mathematical equations in order to generalize and solve more difficult problems. \n",
    "\n",
    "Let's visualize the actual plot and see what this line equation is all about.\n",
    "\n",
    "![Acceptance at unversity](images/acceptance_university.png)\n",
    "\n",
    "Considering our general admissions problem, we have the generalized form of our line equation:\n",
    "![Linear Boundaries](images/linear_boundaries.png)\n",
    "\n",
    "Concept of separating points by a line, where\n",
    "~~~\n",
    "w, W - represent the weights\n",
    "x - points\n",
    "b - bias\n",
    "~~~\n",
    "\n",
    "Essentially this is the equation of the line where we have some vectors (`w1`, `w2`) and (`x1`, `x2`) and we are trying to predict the label `y` whether it is a 1 or 0. e.g. student accepted at university = 1 (above the line) and student rejected = 0 (below the line). The plot is basically the graphical representation of the equation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher dimensions\n",
    "\n",
    "Until now we had to deal with two data points, the test and grades but what if we had another column or 10 other columns?\n",
    "The way we tackle the problem is pretty much the same except that we add those weights and points to our equation so it remains the same.\n",
    "\n",
    "![Higher dimensions](images/higher_dimensions.png)\n",
    "\n",
    "As an example of how the dimensions would be structured (think NumPy), with respect to the `W`, `x` and `b` it would be:\n",
    "- `W:(1 x n)`, `x:(n x 1)`, `b:(1 x 1)`, this is because we need all the columns (the weights) to multiply with all the rows (inputs) and add the bias only once.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron\n",
    "\n",
    "The building block of neural networks. Think of the perceptron as a node that holds the linear equation that we've learned about before, an encoding of the equation into a small graph.\n",
    "\n",
    "What the perceptron does is plot the points and check if it's in the positive and negative area. In the general case, this is how a perceptron looks like.\n",
    "\n",
    "![Perceptron](images/perceptron.png)\n",
    "\n",
    "What is happening in the perceptron is a summation taking all the points, weights and biases following the equation that was defined as `Wx + b`. Then the node checks if the value is 0 or bigger thus returning YES or NO. \n",
    "\n",
    "The node uses a step function that turns everything to 1 if the output is greater than 0 and vice-versa.\n",
    "\n",
    "![Step function](images/step_function.png)\n",
    "\n",
    "As you might notice a perceptron can be seen as a combination of nodes, in this case a linear function (1st node) and a step function (2nd) that is applied to the result of the first node.\n",
    "\n",
    "![Perceptron nodes](images/perceptron_wstep.png)\n",
    "\n",
    "Why is this important? Because there different step functions (activation) that are used, more complex thus it's important to represent the nodes of the perceptron in such a way.\n",
    "\n",
    "So is this the only way to represent represent the bias unit? No, we can represent it in two ways:\n",
    "\n",
    "![Perceptron representation](images/two_ways_represent_perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks\n",
    "\n",
    "What is a neural network or better, why is it called a neural network anyways? To answer that question let's imagine a perceptron and right next to it a neuron (from the brain). The reason why it's called that way is because a perceptron calculates some equation on the input and it outputs a 1 or 0. A neuron receives inputs from dendrites so the what the neuron does is process the inputs (nervous impulse) and then it decides whether it outputs a nervous impulse or not.\n",
    "\n",
    "![Neuron and perceptron](images/nn_neurons.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptrons as Logical Operators\n",
    "\n",
    "In the course, it has been shown that Perceptrons have the property of representing logical operators. Here is how it works, from a table we take a pair of numbers e.g. 1 and 0, these two are taken as input by the AND perceptron. Inside the perceptron imagine that the points get plotted based on their values. The result is pretty much the same as for logical operators in computer science. For AND to output True or 1 in our case, both points have to be 1 and 1 otherwise the output will be 0.\n",
    "\n",
    "![AND_perceptron](images/AND_perceptron.png)\n",
    "\n",
    "AND can be represented by the following equation `1*w1 + 1*w2 + b = 0`, where `w1 = w2 = 1` and `b = -2`, in this case it means that the result is 0 thus for a linear combination it's a 1 as the output.\n",
    "\n",
    "![OR_perceptron](images/OR_perceptron.png)\n",
    "\n",
    "I've explained above how perceptrons can represent logical operators, besides the AND, there is also the OR operator, it works in a similar fashion except for the different **weights** and **bias**. \n",
    "\n",
    "OR can be represented as `1* x1 + 1 * x2 -1 = 0`, where `w1 = w2 = 1`, and `b = -1`\n",
    "\n",
    "Let's go further and explore an aspect mentioned before. We note that OR is very similar to AND, so the question is would it be possible to go from OR to AND by adjusting the parameters? We could think of two ways to achieve that by **increasing the weights** or **decreasing the magnitude of the bias**.\n",
    "\n",
    "Another operator is the NOT operator. It basically returns a 0 as output if input is 1 and returns 1 if input is 0. The other inputs are ignored by the perceptron.\n",
    "\n",
    "Lastly, we have the XOR operator which is a combination of AND, OR, NOT operators. Essentially, an XOR returns a 1 as output if it receives two different inputs e.g. 1 and 0 => 1. \n",
    "\n",
    "![XOR perceptron](images/XOR_perceptron.png)\n",
    "\n",
    " To have a better intuition of how the XOR works, let's build a Multi-Layered Perceptron (MLP), which basically means that we have multiple perceptrons linked together. We have all three operators learned previously AND, OR, NOT and with their help we are going to calculate an XOR. \n",
    "\n",
    "We have 3 perceptrons A, B, C which form the MLP. Now the question is what operators do we need in order to calculate an XOR. Let's start from the end, what input does the XOR need. For starters we would need an OR because we are interested in turning the outputs 1 and 0 into a 1 and it's just the OR does. So what can we combine it with? If you add AND and OR we will have too many of the 1s and too few 0s as input. But what if we had NOT and OR. If you think about it, we can use NOT applied to an AND in order to return 0 as ouput if input is 1 and vice-versa. Just what we needed. Take a look at the table, the first row of 1 and 1 has to be negated thus turning the output into 0, same applies for the last row which leaves us with rows 2 and 3 which we can work with because have an OR. \n",
    "\n",
    "Let's sort this out:\n",
    "- A - AND\n",
    "- B - OR\n",
    "- C - NOT\n",
    "\n",
    "![XOR mlp](images/XOR_mlp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron Trick\n",
    "\n",
    "Imagine that we have a plot with points classified as blue and red depending on which area they are found in as in the image below. But there are there two points that look as if they don't belong. *How do we know if a point is misclassifed? If you carefully look at the color of the point (label) you can notice that they are not in correct area (color)*. Let's assume that our perceptron wasn't adjusted well enough in order to correctly the points. What can we do is make the line of the equation change, the only way we can classify correctly those points is if the line came closer to the misclassifed point eventually going over them. \n",
    "\n",
    "![Misclassifed points](images/split_data_points.png)\n",
    "\n",
    "In order to grasp the math behind how the line actually moves, let's focus on an example where we have a misclassifed point. The point is telling the line to come closer. The way it works is that we can use the value of the points to subtract from the parameters of the line.\n",
    "\n",
    "![Perceptron Trick](images/perceptron_trick_addition.png)\n",
    "\n",
    "Will this solve all of our problems? No. We have to be careful in this case because if we drastically alter the parameters of the equation we might end up misclassifying other points. Our goal is to make the line make small steps towards the point. Enter **learning rate**. We are multiplying the value of the point with the learning rate then we perform the subtraction.\n",
    "\n",
    "![Learning rate](images/learning_rate.png)\n",
    "\n",
    "_Note_: Depending on where the misclassified point is located we'll have to add or subtract.\n",
    "\n",
    "![Point misclassified as negative](images/perceptron_trick_lr_negative.png)\n",
    "\n",
    "What we can do with the learning rate is multiply with the points coordinates thus resulting a line equation with different parameters. The way you can think about it is a sort of factor that helps you move the position of the line. This can be applied to any of our points. Essentially, the parameters and the bias determine where the line of the equation is drawn. This is what is called as the **Perceptron Trick**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron Algorithm\n",
    "\n",
    "We learned how the perceptron trick works conceptually and mathematically, the next goal is to learn how to implement it. The algorithm works this way.\n",
    "```\n",
    "1. Start with random initialized weights: w1, ... wn, b\n",
    "2. For every misclassified point\n",
    "\t2.1. If point = 0 \n",
    "\t\tFor i = 1...n\n",
    "\t\t\tChange wi + a*xi\n",
    "\t\tChange b to b+a\n",
    "\t2.2. If point = 1\n",
    "\t\tFor i = 1...n\n",
    "\t\t\tChange wi - a*xi\n",
    "\t\tChange b to b-a\n",
    "\tRepeat until we have no errors\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the perceptron step works as follows. For a point with coordinates $(p,q)$, label $y$, and prediction given by the equation $\\hat{y}=step(w_{1}x_{1}+w_{2}x_{2}+b)$\n",
    "\n",
    "- If the point is correctly classified, do nothing.\n",
    "- If the point is classified positive, but it has a negative label, subtract $αp,αq,\\alpha p$, \\alpha q$, and α\\alphaα from w1,w2,w_1, w_2,w1​,w2​, and bbb respectively.\n",
    "- If the point is classified negative, but it has a positive label, add αp,αq,\\alpha p, \\alpha q,αp,αq, and α\\alphaα to w1,w2,w_1, w_2,w1​,w2​, and bbb respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    # Fill in code\n",
    "    for i in range(len(X)):\n",
    "        y_hat = prediction(X[i],W,b)\n",
    "        if y[i]-y_hat == 1:\n",
    "            W[0] += X[i][0]*learn_rate\n",
    "            W[1] += X[i][1]*learn_rate\n",
    "            b += learn_rate\n",
    "        elif y[i]-y_hat == -1:\n",
    "            W[0] -= X[i][0]*learn_rate\n",
    "            W[1] -= X[i][1]*learn_rate\n",
    "            b -= learn_rate\n",
    "    return W, b\n",
    "    \n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linear Regions\n",
    "\n",
    "Until now the examples we encountered had a pretty good distinction between the blue and red points. What if we receive additional scores that are different from what we got so far. \n",
    "\n",
    "In the image below we can noticed that our points can't be separated so well by a straight line. What do we do? Unfortunately, the perceptron algorithm will not work this time so in order to obtain for example a curved line our equation will have to be more complex. \n",
    "\n",
    "![Non-Linear regions](images/non_linear_regions.png)\n",
    "\n",
    "### Error Functions\n",
    "\n",
    "A solution to the problem of creating a better line is going to be approached by an error function. What this means is such a function given an input is going to tell us how close the line is from the misclassified point. \n",
    "\n",
    "Error function = Distance, how far we are from the solution.\n",
    "\n",
    "#### Log-loss Error function\n",
    "\n",
    "The concept of an error function is explained by a mountain descent. Remember our goal is to minimize the error by this if you could imagine a hiker trying to descend a mountain and it's looking for the best path.  \n",
    "\n",
    "Error tells us how far we are from the solution, in order to achieve that our error function is going to take small steps in terms of moving the line closer to the misclassified point. Broadly speaking, you could think that we are counting the number of errors and then our function (using derivatives) is taking small steps (thanks to the learning rate) towards the point, achieving the minimum. The points that are the farthest from their region get the biggest penalty (this is explained in the next section). What happens is that the error for all points gets summed. As the line gets closer to the point the penalty is reduced resulting a smaller total error. \n",
    "\n",
    "Until we get to the best solution, we might get stuck into a \"valley\" or better know as *local minima* which gives us the smallest error locally. This is not necessarily a bad thing but we can certainly do better. In order for our function to work properly we have to be sure of two things:\n",
    "- our function can only be continous (in order to pickup variations even if they are very small)\n",
    "- our function also has to be differentiable \n",
    "\n",
    "![Function discrete vs continous](images/error_function_discrete_continous.png)\n",
    "\n",
    "#### Discrete vs Continuous Predictions\n",
    "\n",
    "To obtain continous predictions we have to change our activation function. Until now, we used a simple step function that could output 1 or 0 depending on the input. In order to adjust for the smaller variations, we have to apply a **sigmoid** function: $\\sigma(x) = \\frac{1}{(1+e^{-x})}$. \n",
    "\n",
    "![Activation functions](images/activation_functions_sigmoid.png)\n",
    "\n",
    "- for large positive numbers it outputs values close to 1\n",
    "- for large negative numbers it gives us values close to 0\n",
    "- for numbers that are close to 0, this gives us 0.5 \n",
    "\n",
    "Our perspective of the blue/red regions change as instead of seeing the line as a strong separation, both are actually making up a probability space where depending how far or close the point is from its region it gets a probabiliy.\n",
    "\n",
    "Now, our model in its generalized has the following form: $\\hat{y}=\\sigma(Wx + b)$, with the linear equation inside the activation function, this gives us the prediction and essentially it's the perceptron node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "The softmax function is equivalent to the sigmoid activation function except that it's useful to us when we have 3 or more classes.\n",
    "\n",
    "Scores: $Z_{1},..., Z_{n}$\n",
    "\n",
    "P(class i) = $\\frac{e^{Z_{i}}}{e^{Zi}+...+e^{Z_{n}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09003057317038046, 0.24472847105479764, 0.6652409557748219]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(L):\n",
    "    expL = np.exp(L)\n",
    "    sumExpL = sum(expL)\n",
    "    result = []\n",
    "    for i in expL:\n",
    "        result.append(i*1.0/sumExpL)\n",
    "    return result\n",
    "\n",
    "L=[5,6,7]\n",
    "softmax(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "This a technique applied for data that is not numerical. In data processing it might happen that we deal with multiple classes and text as input instead of actual numbers.\n",
    "\n",
    "How it works? We're essentially creating a column/variable for every category that we have in the data and for each occurence we assign the number 1, otherwise 0. Just like binary :)\n",
    "\n",
    "![One-hot-encoding](images/one_hot_encoding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood\n",
    "\n",
    "In the case of two or more models how do we decide which one is better? This is where Maximum Likelihood comes in, we pick the model that gives the existing labels the highest probability. As an example the maximization is shown as the product of the independent probabilities.\n",
    "\n",
    "One thing to not is that if we have too many numbers the product ends up being very tiny and if a number changes, the product drastically changes. In order to fix that, we are going to use a summation, specifically **logarithms** as this can help us sum a lot of numbers: e.g. $\\log(ab) = \\log(a) + log(b)$. For convention, natural logs are used instead of log(10).\n",
    "\n",
    "### Cross Entropy\n",
    "\n",
    "Since the natural log (ln) of a number between 0 and 1 results in a negative number, we'll have to take the negative of the natural log of the probability. If we the values of the probabilities for each model then we'll get a distinct value for each of them which is essentially the **cross entropy**. How to decide on what is good and what is bad?\n",
    "\n",
    "- A bad model = high cross entropy\n",
    "- A good model = low cross entroy\n",
    "\n",
    "This makes sense as a good model gives us a high probability, and a low probability gets a high number because the natural log turn a low probability to a very low number. \n",
    "\n",
    "Think of the negatives of the logarithm as the error of each point. A point that is correctly classified will have a small error therefore a cross entropy will tell us if a model is good or bad.\n",
    "\n",
    "The goal has changed from maximizing probability to **minimizing cross entropy**. What this suggests is a relationship between the events and the probabilities telling us how likely is that the events happened because of the probabilities.\n",
    "\n",
    "Cross Entropy = $-\\sum_{i=1}^{m} y_{i}ln(p_{i})+(1-y_{i})ln(1-p_{i})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.828313737302301"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Write a function that takes as input two lists Y, P,\n",
    "# and returns the float corresponding to their cross-entropy.\n",
    "def cross_entropy(Y, P):\n",
    "    pre_sum = []\n",
    "    for i in range(len(Y)):\n",
    "        pre_sum.append(Y[i] * np.log(P[i]) + (1-Y[i]) * np.log(1-P[i]))\n",
    "    return -np.sum(pre_sum)\n",
    "\n",
    "Y=[1,0,1,1] \n",
    "P=[0.4,0.6,0.1,0.5]\n",
    "\n",
    "cross_entropy(Y,P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to remember in Cross Entropy is that order matters. Example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69\n",
      "5.12\n"
     ]
    }
   ],
   "source": [
    "Y=[1,1,0]\n",
    "P=(0.8,0.7,0.1)\n",
    "print(round(cross_entropy(Y,P),2))\n",
    "\n",
    "Y2=[0,0,1]\n",
    "P2=(0.8,0.7,0.1)\n",
    "print(round(cross_entropy(Y2,P2),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Entropy isn't limited to what was presented so far. If we are confronted with the situation where we have multiple classes for calculating the loss we can use the **Multi-Class Cross Entropy** = $-\\sum_{j=1}^{n}-\\sum_{i=1}^{m} y_{ij} ln(p_{ij})$, with `m` being the number of classes. We are only adding the probabilities of the events that have occured.\n",
    "\n",
    "The Multi-Class CE works when `m=2` as in for binary classification. I came across two interesting explanations:  https://datascience.stackexchange.com/questions/9302/the-cross-entropy-error-function-in-neural-networks. \n",
    "And here: https://gombru.github.io/2018/05/23/cross_entropy_loss/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "A short recap. Our classifier works in the following manner:\n",
    "- Take your data\n",
    "- Pick a random model\n",
    "- Calculate the error\n",
    "- Minimize the error, and obtain a better model\n",
    "\n",
    "The first two steps are pretty obvious, how about the other two? \n",
    "\n",
    "1. We previously learned about how to calculate the error using Cross Entropy. The $\\hat{y}$ represents our prediction function: \n",
    "\n",
    "$$-\\frac{1}{m}\\sum_{i=1}^{m}(1-y_{i})(ln(1-\\hat{y_{i}}))+(y_{i}ln(\\hat{y_{i}}))$$\n",
    "\n",
    "2. Because $\\hat{y}$ is our sigmoid model then what were are actually doing is updating the weights and bias since they are input of our model. As we learned earlier, in order to minimize the error for every misclassified point we are going to use gradient descent:\n",
    "\n",
    "$$E(W,b)= -\\frac{1}{m}\\sum_{i=1}^{m}(1-y_{i})(ln(1-\\sigma(W^{i}+b))+y_{i}ln(\\sigma(W^{i}+b)$$\n",
    "\n",
    "The example above works for a binary classification, if we had multiple classes then we could use a multi-class cross entropy for calculating the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "The way Gradient Descent (GD) works is similar to the perceptron algorithm. It involves the error and the weights, essentially the gradient tells us at a certain point in what direction does the error increase the most so since our goal is to minimize it, the negative of the gradient is showing us in which direction we want to move in order to decrease the error function the most. This process is repeated until we get to the minimum.\n",
    "\n",
    "![Gradient descent](images/gradient_descent_calculation.png)\n",
    "\n",
    "A important aspect to notice is that if you break it down, the GD is a scalar times the coordinates of the points (weights, points, bias), the scalar being a multiple of the difference between label and prediction. \n",
    "\n",
    "All of it has an important significance, that the **closer the label to the prediction the smaller the gradient**, and **the farther the label from the prediction the larger the gradient**. E.g. if the point is close to the gradient then the gradient is smaller, otherwise it will be larger. This is where we can observe that it's similar to the perceptron algorithm.\n",
    "\n",
    "#### Gradient Descent Step\n",
    "\n",
    "Therefore, since the gradient descent step simply consists in subtracting a multiple of the gradient of the error function at every point, then this updates the weights in the following way:\n",
    "\n",
    "$w_{i}′\\leftarrow w_{i}−\\alpha[−(y−\\hat{y})x_{i}]$\n",
    "\n",
    "which is equivalent to\n",
    "\n",
    "$w_{i}′\\leftarrow w_{i}+\\alpha(y−\\hat{y})x_{i}$\n",
    "\n",
    "Similarly, it updates the bias in the following way:\n",
    "\n",
    "$b′\\leftarrow b+\\alpha(y−\\hat{y})$\n",
    "\n",
    "#### Gradient Descent Algorithm\n",
    "\n",
    "The algorithm works in the following way:\n",
    "\n",
    "1. Start with random weights $(w_{1},...w_{n},b)$\n",
    "2. For every point $(x_{i},..., x_{n})$\n",
    "    1. For i = 1...n\n",
    "        1. Update weight: $w_{i}′\\leftarrow w_{i}-\\alpha(y−\\hat{y})x_{i}$\n",
    "        2. Update weight: $b′\\leftarrow b-\\alpha(y−\\hat{y})$\n",
    "3. Repeat until there is no error\n",
    "\n",
    "An implementation of the Gradient Descent algorithm can be found in this [notebook](GradientDescent.ipynb).\n",
    "\n",
    "#### Perceptron vs Gradient Descent\n",
    "\n",
    "The main difference between the two is that a perceptron handles only the misclassified points, the 1s and the 0s, meanwhile the GD not only does it adjust the line so that the point is correctly classified, it also moves the line further away from a correctly classified point thus improving its probability. In the GD equation $\\hat{y}$ can take any value between 0 and 1, thus allowing such flexibility, while in the perceptron algorithm it can only be 1 or 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linear Models\n",
    "\n",
    "#### Neural Networks\n",
    "\n",
    "The problem with the equations we've used is that they can only separate/classify points to a certain degree which is why Neural Networks are used, to create a probability region.\n",
    "\n",
    "![Combine perceptrons](images/combined_perceptrons.png)\n",
    "\n",
    "To get there we combine perceptrons in order to create a more complex neural network. Essentially, we are getting the best of both worlds in this case. What happens is that the perceptrons are multiplied with their weights and bias and then get added resulting into an output value that is transformed into a probability by the sigmoid function.\n",
    "\n",
    "Neural Networks can be combined, specifically the output of one node can be passed to another node and so on thus we can actually see that these networks have some sort of architecture composed of: \n",
    "- input layers (weights, bias)\n",
    "- hidden layers (model)\n",
    "- output (probabilities)\n",
    "\n",
    "Neural networks with a lot of nodes are called Deep Neural Networks and end up having a very complex architecture. Moreover, they are not limited to a binary classification and can output the probabilities for a number of classes, essentially the number of nodes in the last layer (output) is increased to match the number of classes that we need.\n",
    "\n",
    "![NN Multiclass](images/nn_multiclass.png)\n",
    "\n",
    "#### Feedforward\n",
    "\n",
    "This is the process used by a neural network to turn the input into output. Below you can see the process of using feedforward to output the prediction of our neural network and it represents an essential part of training a network.\n",
    "\n",
    "![Feed forward](images/feedforward_prediction.png)\n",
    "\n",
    "What happens at the end of the output is getting an error function to calculate how far is the prediction, information used for improvement.\n",
    "\n",
    "$$E(W,b)= -\\frac{1}{m}\\sum_{i=1}^{m}y_{i}ln(\\hat{y})+(1-y_{i})ln(1-\\hat{y})$$\n",
    "\n",
    "\n",
    "#### Backpropagation\n",
    "\n",
    "The key for training a neural network. It refers to updating the weights and biases from the nodes coming from the model as well as from the input to the model thus improving the model based on which model has a better prediction of the model.\n",
    "\n",
    "Summary of backpropagation: \n",
    "- Doing a feedforward operation.\n",
    "- Comparing the output of the model with the desired output.\n",
    "- Calculating the error.\n",
    "- Running the feedforward operation backwards (backpropagation) to spread the error to each of the weights.\n",
    "- Use this to update the weights, and get a better model.\n",
    "- Continue this until we have a model that is good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
