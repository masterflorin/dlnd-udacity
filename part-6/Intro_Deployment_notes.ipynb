{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the machine learning workflow?\n",
    "\n",
    "<img src=\"part-6_images/ml_workflow.png\" alt=\"Machine Learning workflow\" style=\"width: 500px;\">\n",
    "\n",
    "### How does deployment fit into the machine learning workflow?\n",
    "\n",
    "<img src=\"part-6_images/mlworkflow-deployment-chars.png\" alt=\"Machine Learning workflow - Deployment\" style=\"width: 500px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker workflow: https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-mlconcepts.html\n",
    "\n",
    "GCP workflow: https://cloud.google.com/ml-engine/docs/tensorflow/ml-solutions-overview\n",
    "\n",
    "Azure workflow: https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is cloud computing?\n",
    "\n",
    "Storing your data on a server e.g. Google Drive, OneDrive instead of flash drive or HDD\n",
    "\n",
    "### Why would we use cloud computing for deploying machine learning models?\n",
    "\n",
    "*Benefits of Cloud Computing*\n",
    "\n",
    "- Reduced Investments and Proportional Costs (providing cost reduction)\n",
    "- Increased Scalability (providing simplified capacity planning)\n",
    "- Increased Availability and Reliability (providing organizational agility)\n",
    "\n",
    "*Risks*\n",
    "\n",
    "- (Potential) Increase in Security Vulnerabilities\n",
    "- Reduced Operational Governance Control (over cloud resources)\n",
    "- Limited Portability Between Cloud Providers\n",
    "- Multi-regional Compliance and Legal Issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does it mean for a model to be deployed?\n",
    "\n",
    "Deployment to production can simply be thought of as a method that integrates a machine learning model into an existing production environment so that the model can be used to make decisions or predictions based upon data input into the model. \n",
    "\n",
    "#### Paths to Deployment:\n",
    "\n",
    "1. Python model is recoded into the programming language of the production environment.\n",
    "2. Model is coded in Predictive Model Markup Language (PMML) or Portable Format Analytics (PFA).\n",
    "3. Python model is converted into a format that can be used in the production environment.\n",
    "\n",
    "The last option is the easiest and fastest way to move a Python model from modeling directly to deployment.\n",
    "\n",
    "e.g. The third method that's most similar to what’s used for deployment within Amazon’s SageMaker.\n",
    "\n",
    "Most popular machine learning software frameworks, like PyTorch, TensorFlow, SciKit-Learn, have methods that will convert Python models into intermediate standard format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Environments\n",
    "\n",
    "Production Environment is just the application that customers use to receive predictions from the deployed model.\n",
    "\n",
    "<img src=\"part-6_images/prod_environment.png\" alt=\"Production environment\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Production Environment and the Endpoint\n",
    "\n",
    "The endpoint is an interface that:\n",
    "\n",
    "- Allows the application to send user data to the model and\n",
    "- Receives predictions back from the model based upon that user data.\n",
    "\n",
    "One way to think of the endpoint that acts as this interface, is to think of a Python program where:\n",
    "\n",
    "- the endpoint itself is like a function call\n",
    "- the function itself would be the model and\n",
    "- the Python program is the application.\n",
    "\n",
    "<img src=\"part-6_images/endpointprogram-2.png\" alt=\"Endpoint as a program\" style=\"width: 500px;\"/>\n",
    "\n",
    "### Endpoint and REST API\n",
    "\n",
    "Communication between the application and the model is done through the endpoint where the endpoint is an **API**. \n",
    "- An API is a set of rules that enable programs to communicate with each other\n",
    "- The API uses a REST framework that uses HTTP **requests** and **responses** to enable communication\n",
    "\n",
    "<img src=\"part-6_images/httpmethods.png\" alt=\"HTTP methods\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "The **HTTP request** that’s sent from your application to your model is composed of four parts:\n",
    "- endpoint, which is a URL\n",
    "- HTTP method, e.g. GET, POST\n",
    "- HTTP header, contains additional information such as the format\n",
    "- Message, will contain the user's data\n",
    "\n",
    "The **HTTP response** sent from your model to your application is composed of three parts:\n",
    "- HTTP Status Code, e.g. 200\n",
    "- HTTP header, format\n",
    "- Message, will contain the predictions of the model\n",
    "\n",
    "Often the user's data and the prediction will be in JSON or CSV format.\n",
    "\n",
    "Finally, the application acts like an intermediate layer which means that it has to:\n",
    "- To format the user’s data in a way that can be easily put into the HTTP request message and used by the model. \n",
    "- To translate the predictions from the HTTP response message in a way that’s easy for the application user’s to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containers\n",
    "\n",
    "Both the application and model require computing environment that can be run and is available. This can be achieved by the use of **containers** which are essentially collection that is standardized to have all the software/libraries that it need to run an application A very popular example of this is Docker.\n",
    "\n",
    "A container, Docker, for example:\n",
    "- Can contain all types of different software.\n",
    "- The structure of a Docker container enables the container to be created, saved, used, and deleted through a set of common tools. \n",
    "- The common tool set works with any container regardless of the software the container contains. \n",
    "\n",
    "<img src=\"part-6_images/container-1.png\" alt=\"Container architecture\" style=\"width: 600px;\"/>\n",
    "\n",
    "A container can easily created by a script file that has the necessary instructions to replicate a particular container. \n",
    "\n",
    "<img src=\"part-6_images/container-2.png\" alt=\"Container architecture 2\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the crucial characteristics associated with deploying models?\n",
    "\n",
    "- Model Versioning, allows us to see the model's version\n",
    "- Model Monitoring, easily monitor deployed models\n",
    "- Updating and Routing, ability to easily update a model's performance if it fails, and allow to test the model's performance compared to other variants through routing \n",
    "- Predictions\n",
    "    - On-Demand - allows the users to retrieve predictions in real time\n",
    "    - Batch - for business decisions that are not required real-time. For example, imagine a business uses a complex model to predict customer satisfaction across a number of their products and they need these estimates for a weekly report. This would require processing customer data through a batch prediction request on a weekly basis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
