{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN's are most often associated with text processing and text generation because of the way sentences are structured as a sequence of words!\n",
    "\n",
    "So far the simple NNs and CNNs focus on the current inputs, meanwhile an RNN differentiates itself from this by having memory of past inputs which makes it great for tasks where predicting the next word in a sentence is the output of the network.\n",
    "\n",
    "### RNN History\n",
    "\n",
    "First attempts:\n",
    "\n",
    "- [TDNN](https://en.wikipedia.org/wiki/Time_delay_neural_network)\n",
    "- [Elman networks](https://en.wikipedia.org/wiki/Recurrent_neural_network#Elman_networks_and_Jordan_networks)\n",
    "- [LSTM](http://www.bioinf.jku.at/publications/older/2604.pdf)\n",
    "\n",
    "RNN still have a big flaw, the **vanishing gradient** that previous networks haven't resolved. While an RNN can captures relationships from several steps in the past if it goes too far the weight updates become very small as the gradient becomes geometrically smaller as the number of steps increases thus backpropagation is working with very small derivatives. \n",
    "\n",
    "Long Short-Term Memory Cells (LSTMs) and Gated Recurrent Units (GRUs) give a solution to the vanishing gradient problem, by helping us apply networks that have temporal dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network-Reminder\n",
    "\n",
    "The goal is to decide what to decide what goes inside the black box (e.g. neural network, other algorithms) but what we really want is **finding the optimal set of weights**.\n",
    "\n",
    "There are two phases:\n",
    "- Training (includes feedforward and backpropagation)\n",
    "- Evaluation\n",
    "\n",
    "During training our goal is to find the optimal set of weights that would best map the inputs to the desired outputs. In evaluation, we test our network with inputs that it has never seen before.\n",
    "\n",
    "### Feedforward\n",
    "\n",
    "![Feedforward from inputs to hidden layers](part-4_images/feedforward1.png)\n",
    "\n",
    "1. Calculating the value of the hidden states.\n",
    "\n",
    "Our first step is finding $hat_{h}$ (the hidden layers) and this is done by multiplying all inputs with their corresponding weights, followed by a summation. \n",
    "\n",
    "![Finding h hat](part-4_images/inputs_weights.png)\n",
    "\n",
    "After we find $h'$ we need an activation function to finalize the computation of the hidden layer's values which is generally noted as $\\hat{h} = \\Phi(hat{x}W^1)$ or $\\hat{h} = \\Phi(h')$\n",
    "\n",
    "![Calculating h](part-4_images/calc_hidden_layers.png)\n",
    "\n",
    "Resource on activation functions: [here](https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions) and [here](https://theclevermachine.wordpress.com/tag/tanh-function/).\n",
    "\n",
    "2. Calculating the values of the Outputs\n",
    "\n",
    "What happens next is the hidden layers get multiplied with another set of weights. Essentially, each new layer in an neural network is calculated by a vector by matrix multiplication, where the vector represents the inputs to the new layer and the matrix is the one connecting these new inputs to the next layer.\n",
    "\n",
    "Below an example of how the calculations would be done if we had 3 hidden layers.\n",
    "\n",
    "![Generalized output calculation](part-4_images/generalized_calc_outputs.png)\n",
    "\n",
    "In some applications it can be beneficial to use a softmax function (if we want all output values to be between zero and 1, and their sum to be 1).\n",
    "\n",
    "Now, what comes next is determining the loss or how far is the generated output from the real label. This is done with the help of a loss function which is essential for backpropagation to work. \n",
    "\n",
    "The two error functions that are most commonly used are the **Mean Squared Error (MSE)** (usually used in regression problems) and the **cross entropy** (usually used in classification problems).\n",
    "\n",
    "Summary:\n",
    "\n",
    "On a simple example: \n",
    "- A single input x\n",
    "- Two hidden layers with M and N neurons\n",
    "- A singe output\n",
    "\n",
    "To calculate the number of multiplications needed for a single feedforward pass, we can break down the network to three steps:\n",
    "\n",
    "Step 1: From the single input to the first hidden layer\n",
    "\n",
    "Step 2: From the first hidden layer to the second hidden layer\n",
    "\n",
    "Step 3: From the second hidden layer to the single output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation\n",
    "\n",
    "To better picture how backpropagation works let's picture how would the weights change, since that's what we are interested as the error is getting smaller. What is happening? \n",
    "\n",
    "![Gradient considerations](part-4_images/gradient_considerations.png)\n",
    "\n",
    "In the example above, if the weight was on the other side of the valley then our weights would have to become smaller in order to get to the bottom.\n",
    "\n",
    "![Gradient considerations 2](part-4_images/gradient_considerations2.png)\n",
    "\n",
    "A closer look at updating the weight.\n",
    "\n",
    "![Weight update](part-4_images/weight_update.png)\n",
    "\n",
    "As a summary, backprop involves two steps:\n",
    "- calculate the partial derivative of the error E w.r.t to each weights\n",
    "- adjust the weights according to the calculated value of delta Wij\n",
    "\n",
    "where \n",
    "- the superscript (k) indicates that the weight connects layer k to layer k+1. \n",
    "- he updated value $\\Delta W_{ij}^k $ is calculated through the use of the gradient calculation\n",
    "\n",
    "\n",
    "![Backpropagation summary](part-4_images/backpropagation_summary.png)\n",
    "\n",
    "\n",
    "The chain of thought in the weight updating process is as follows:\n",
    "\n",
    "To update the weights, we need the network error. To find the network error, we need the network output, and to find the network output we need the value of the hidden layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional notes on derivatives and partial derivatives\n",
    "\n",
    "https://www.ics.uci.edu/~pjsadows/notes.pdf\n",
    "http://www.columbia.edu/itc/sipa/math/calc_rules_multivar.html\n",
    "https://math.dartmouth.edu/archive/m23f04/public_html/PartialDifferentiation.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN (keyword: temporal)\n",
    "\n",
    "They are similar to Feed-Forward Neural Network (FFNN) except for a some fundamental differences:\n",
    "- in RNN, we have a concept called **memory** which is essentially the output of a hidden layer neuron that is also an input for another hidden layer \n",
    "- **sequences**, which are the input in a training phase\n",
    "\n",
    "<img src=\"part-4_images/elman-network.png\" alt=\"Elman Network\" style=\"width: 350px;\"/>\n",
    "\n",
    "RNNs use feedback as a way of calculating the hidden layers, the input not only consists of the current point and weights but also the **state**, the memory from the previous hidden layer neuron.\n",
    "\n",
    "In comparison to feedforward neural networks, an RNN's appearance is a bit different to acommodate the state. This case is known as a **folded** model. \n",
    "\n",
    "<img src=\"part-4_images/rnn-folded.png\" alt=\"RNN Folded\" style=\"width: 550px;\"/>\n",
    "\n",
    "Wx -  is the weight matrix connecting the inputs to the state layer.\n",
    "\n",
    "Wy - is the weight matrix connecting the state layer to the output layer.\n",
    "\n",
    "Ws - represents the weight matrix connecting the state from the previous timestep to the state in the current timestep.\n",
    "\n",
    "As mentioned abbove, in RNNs the state layer depended on the current inputs, their corresponding weights, the activation function and also on the previous state:\n",
    "\n",
    "<img src=\"part-4_images/rnn-activation.png\" alt=\"RNN activation\" style=\"width: 350px;\"/>\n",
    "\n",
    "The output vector is calculated exactly the same as in FFNNs.\n",
    "\n",
    "#### Unfolded model\n",
    "\n",
    "The unfolded model is a cleaner way to visualize an RNN architecture. In this example, we can notice how the input is passed through the network into different states.\n",
    "\n",
    "<img src=\"part-4_images/rnn-unfolded.png\" alt=\"RNN unfolded\" style=\"width: 550px;\"/>\n",
    "\n",
    "### How do we train an RNN? \n",
    "\n",
    "#### Backpropagation Through Time (BPTT) - keyword: accumulation\n",
    "\n",
    "Recap notations for backpropagation\n",
    "\n",
    "<img src=\"part-4_images/recap_backprop_ffnn.png\" alt=\"FFNN steps\" style=\"width: 550px;\"/>\n",
    "\n",
    "In BPTT we train the network at timestep t as well as take into account all of the previous timesteps. \n",
    "\n",
    "In this example we will focus on the BPTT process for time step t=3. You will see that in order to adjust all three weight matrices, Wx, Ws, Wx, we need to consider timestep 3 as well as timestep 2 and timestep 1.\n",
    "\n",
    "<img src=\"part-4_images/bptt-folded-t3.png\" alt=\"RNN backpropagation through time step 3\" style=\"width: 250px;\"/>\n",
    "\n",
    "To update each weight matrix, we need to find the partial derivatives of the Loss Function at time 3, as a function of all of the weight matrices. We will modify each matrix using gradient descent while considering the previous timesteps.\n",
    "\n",
    "For a better understanding of how backpropagation works, the unfolded model is used. A simple RNN example with 3 states and 1 output is used. To calculate the BPTT at t-3 you do:\n",
    "\n",
    "1. Gradient calculations to adjust Wy\n",
    "2. Gradient calculations to adjust Ws\n",
    "3. Gradient calculations to adjust Wx\n",
    "\n",
    "At step 1: \n",
    "\n",
    "The partial derivative of the Loss Function with respect to Wy is found by a simple one step chain rule.\n",
    "\n",
    "<img src=\"part-4_images/bptt-step1.png\" alt=\"RNN backpropagation step 1\" style=\"width: 250px;\"/>\n",
    "\n",
    "To adjust Ws: we have to go back to the first state as s3 depends s2, and s2 depends on s1. In BPTT we will take into account every gradient stemming from each state, accumulating all of these contributions.\n",
    "\n",
    "<img src=\"part-4_images/bptt-adjust-ws.png\" alt=\"RNN backpropagation step 1\" style=\"width: 550px; height: 300px;\"/>\n",
    "\n",
    "You will find that as we propagate a step back, we have an additional partial derivatives to consider in the chain rule. Mathematically this can be easily written in the following general equation for adjusting Ws using BPTT:\n",
    "\n",
    "<img src=\"part-4_images/bptt-ws-generalized.png\" alt=\"RNN bptt generalized adjust ws\" style=\"width: 250px;\"/>\n",
    "\n",
    "As mentioned in this lesson, capturing relationships that span more than 8 to 10 steps back is practically impossible due to the vanishing gradient problem.\n",
    "\n",
    "To adjust Wx:\n",
    "\n",
    "When calculating the partial derivative of the Loss Function with respect to to Wx we need to consider, again, all of the states contributing to the output. This process is similar to the one used for updating Ws.\n",
    "\n",
    "<img src=\"part-4_images/bptt-adjust-wx.png\" alt=\"RNN bptt wx\" style=\"width: 550px; height: 300px\"/>\n",
    "\n",
    "As a generalized form:\n",
    "\n",
    "<img src=\"part-4_images/bptt-wx-generalized.png\" alt=\"RNN generalized wx\" style=\"width: 250px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general derivation of the BPTT calculation can be displayed the following way:\n",
    "\n",
    "<img src=\"part-4_images/bptt-general-derivation.png\" alt=\"BPTT generalized derivation\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Summary\n",
    "\n",
    "- in RNNs the current state depends on the input as well as the previous states, with the use of an activation function.\n",
    "- the current output is a simple linear combination of the current state elements with the corresponding weight matrix (a softmax activation function is optional)\n",
    "- RNN can be represented as a folded or a unfolded model\n",
    "\n",
    "<img src=\"part-4_images/rnn_folded_unfolded.png\" alt=\"RNN folded and unfolded representation\" style=\"width: 650px;\"/>\n",
    "\n",
    "- gradient calculations are done for the purpose of updating the weights matrices\n",
    "- backpropagation through time is used in order to accumulate all the contributions from previous steps\n",
    "- when training RNNs using BPTT, we can choose to use mini-batches, where we update the weights in batches periodically\n",
    "- we calculate the gradient for each step but do not update the weights right away. Instead, we update the weights once every fixed number of steps.\n",
    "- if we backpropagate more than ~10 timesteps, the gradient will become too small (vanishing gradient problem)\n",
    "- in RNNs we can also have the opposite problem, called the exploding gradient problem, in which the value of the gradient grows uncontrollably. A simple solution for the exploding gradient problem is [Gradient Clipping](https://arxiv.org/abs/1211.5063)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short note on Long Short-Term Memory (LSTM) cells\n",
    "\n",
    "- LSTM solves the vanishing gradient problem by introducing the concept of LSTM cells. Instead of performing just an activation calculation for the neuron it does 4 different calculations.\n",
    "- It is fully differentiable, therefore gives us the option of easily using backpropagation when updating the weights.\n",
    "- It can backpropagate through many, many time steps \n",
    "- It can decide what to keep, what to forget and what to pass to the next neuron\n",
    "\n",
    "<img src=\"part-4_images/lstm_cell.png\" alt=\"LSTM close up\" style=\"width: 650px;\"/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
