{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to Image Translation\n",
    "\n",
    "Is a specific task that involves moving an image from one domain to another.\n",
    "\n",
    "<img src=\"part-5_images/image2image_translation.png\" alt=\"Image to Image translation\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing Loss Functions\n",
    "\n",
    "One of the most challenging aspects in deep learning is finding a good loss function, also known as the **objective function.** This is often expressed as a function that measures the difference between a prediction $\\hat{y}$ and a true target y.\n",
    "\n",
    "A very common function is the cross entropy loss, where for binary classification there is the binary cross entropy loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANs recap\n",
    "\n",
    "<img src=\"part-5_images/gans_recap.png\" alt=\"GANs recap\" style=\"width: 500px;\">\n",
    "\n",
    "*Latent means \"hidden\" or \"concealed\". In the context of neural networks, a latent space often means a feature space, and a latent vector is just a compressed, feature-level representation of an image!*\n",
    "\n",
    "For example, when you created a simple autoencoder, the outputs that connected the encoder and decoder portion of a network made up a compressed representation that could also be referred to as a latent vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pix2Pix Generator\n",
    "\n",
    "While a GAN aims to generate a realistic image from a latent factor z, in a image to image translate task, the goal is to locate an input image and produce a desired output. \n",
    "\n",
    "<img src=\"part-5_images/paired_img_data.png\" alt=\"Paired image dataset\" style=\"width: 500px;\">\n",
    "\n",
    "The architecture can be found in the original paper: https://arxiv.org/pdf/1611.07004.pdf\n",
    "\n",
    "To be more precise, we want the generator (G) to learn the mapping from x to y, where G is a neural network and we want G(x) to generate an output that is indistinguishable from y. That's why the dataset used is a pair of x, y. \n",
    "\n",
    "This is what is known as **CGAN (Conditional Generative Adversarial Network)** to learn the mapping from input to an output image and while it's composed of a Generator and a Discriminator there are a few differences.\n",
    "\n",
    "**How does the generator actually work?**\n",
    "\n",
    "<img src=\"part-5_images/cgan_generator.png\" alt=\"CGAN Generator\" style=\"width: 500px;\">\n",
    "\n",
    "Instead of using usual neural network that generates from input z -> a representation, the CGAN applies a transformation that is similar to an autoencoder. Essentially, the encoder learns how to distill some information about the content of the input image and encode it into a smaller feature representation then the decoder reverses the operations by looking at the sketch image representation and output something realistic.\n",
    "\n",
    "In short, it takes an input image and based on that it produces a target image as realistic as possible.\n",
    "\n",
    "Pix2pix high resolution paper: https://tcwang0509.github.io/pix2pixHD/\n",
    "\n",
    "### Pix2Pix Discriminator\n",
    "\n",
    "The discriminator is modified in such a way that instead of identifiying as fake or real images it looks at a pair of input-output images and **output a value for a fake pair or a real pair**.\n",
    "\n",
    "<img src=\"part-5_images/cgan_discriminator.png\" alt=\"CGAN Discriminator\" style=\"width: 500px;\">\n",
    "\n",
    "Based on a pair of images, it tries to determine whether the image is generated or not. The generator's weights are also adjusted based on the output of the discriminator. The discriminator is acting as the loss function and is conditional on both the input and output images to the generator which is why this is called **conditional gan.** \n",
    "\n",
    "A Pix2Pix summary: https://neurohive.io/en/popular-networks/pix2pix-image-to-image-translation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
